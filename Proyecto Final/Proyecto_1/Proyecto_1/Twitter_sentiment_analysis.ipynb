{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- José Francisco Pacheco Quintana A01373488\n",
    "- Uriel Fuentes Cavazos A00820592\n",
    "- Eloy Hernández Lúa A01066325\n",
    "- Yasuo Ignacio Maidana Perez A01328427"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liberías y módulos a importar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "from matplotlib import style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no se tienen instalados los paquetes adicionales de la librería nltk, se instalan con la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dejó esta celda a propósito para detener el jupyter notebook. Después de esta celda, se muestra el procedimiento para obtener los modelos ya entrenados. Para ver los modelos funcionando, se puede correr el jupyter [Aquí](#cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando el dataset para entrenamiento. Se puede utilizar otro dataset para entrenar las funciones. Se recomienda tener los ejemplos positivos y negativos en archivos diferentes para que estos puedan ser importados y utilizados con las siguiente celdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_pos = open('positive.txt', 'r').read()\n",
    "short_neg = open('negative.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for r in short_pos.split('\\n'):\n",
    "    documents.append( (r, 'pos') )\n",
    "\n",
    "for r in short_neg.split('\\n'):\n",
    "    documents.append( (r, 'neg') )\n",
    "\n",
    "all_words = []\n",
    "\n",
    "short_pos_words = word_tokenize(short_pos)\n",
    "short_neg_words = word_tokenize(short_neg)\n",
    "\n",
    "for w in short_pos_words:\n",
    "    all_words.append(w.lower())\n",
    "    \n",
    "for w in short_neg_words:\n",
    "    all_words.append(w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "word_features = list(all_words.keys())[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets= [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "random.shuffle(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = featuresets[:10000]\n",
    "testing_set = featuresets[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Modelos</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presentan los modelos a utilizar para la clasificación de tweets. Estas celdas toman tiempo en correr, dependiendo del tamaño de los batches de entrenamiento y de testing, por lo que se recomienda cargar los modelos ya preentrenados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original nltk Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Naive Bayes Algorithm accuracy percent:', (nltk.classify.accuracy(classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print('MNB_classifier accuracy percent:', (nltk.classify.accuracy(MNB_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print('BernoulliNB_classifier accuracy percent:', (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print('LogisticRegression_classifier accuracy percent:', (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Vector Machine, with stochastic gradient descent, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print('SGDClassifier_classifier accuracy percent:', (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Support Vector Machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print('LinearSVC_classifier accuracy percent:', (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu Support Vector Machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print('NuSVC_classifier accuracy percent:', (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting system: takes a vote from each of the classifiers and it will classify the input as positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    \n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "    \n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voted_classifier = VoteClassifier(classifier, \n",
    "                                  NuSVC_classifier, \n",
    "                                  LinearSVC_classifier, \n",
    "                                  SGDClassifier_classifier, \n",
    "                                  MNB_classifier, \n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('voted_classifier accuracy percent:', (nltk.classify.accuracy(voted_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification:', voted_classifier.classify(testing_set[1][0]), 'Confidence%:', voted_classifier.confidence(testing_set[0][0]))\n",
    "print('Classification:', voted_classifier.classify(testing_set[2][0]), 'Confidence%:', voted_classifier.confidence(testing_set[1][0]))\n",
    "print('Classification:', voted_classifier.classify(testing_set[3][0]), 'Confidence%:', voted_classifier.confidence(testing_set[2][0]))\n",
    "print('Classification:', voted_classifier.classify(testing_set[4][0]), 'Confidence%:', voted_classifier.confidence(testing_set[3][0]))\n",
    "print('Classification:', voted_classifier.classify(testing_set[5][0]), 'Confidence%:', voted_classifier.confidence(testing_set[4][0]))\n",
    "print('Classification:', voted_classifier.classify(testing_set[6][0]), 'Confidence%:', voted_classifier.confidence(testing_set[5][0]))\n",
    "print('Classification:', voted_classifier.classify(testing_set[7][0]), 'Confidence%:', voted_classifier.confidence(testing_set[6][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#J = adjective, R = adverb, V = verb\n",
    "#allowed_word_types = ['J', 'R', 'V']\n",
    "allowed_word_types = ['J']\n",
    "\n",
    "for p in short_pos.split('\\n'):\n",
    "    documents.append( (p, 'pos') )\n",
    "    words = word_tokenize(p)\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "for p in short_neg.split('\\n'):\n",
    "    documents.append( (p, 'neg') )\n",
    "    words = word_tokenize(p)\n",
    "    neg = nltk.pos_tag(words)\n",
    "    for w in neg:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_documents = open('pickled_algos/documents.pickle', 'wb')\n",
    "pickle.dump(documents, save_documents)\n",
    "save_documents.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docu = open('pickled_algos/documents.pickle', 'rb')\n",
    "doc = pickle.load(docu)\n",
    "docu.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_word_features = open('pickled_algos/word_features5k.pickle', 'wb')\n",
    "pickle.dump(word_features, save_word_features)\n",
    "save_word_features.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_classifier = open('pickled_algos/originalNB.pickle', 'wb')\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_classifier = open('pickled_algos/BernoulliNB.pickle', 'wb')\n",
    "pickle.dump(BernoulliNB_classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_classifier = open('pickled_algos/LogisticReg.pickle', 'wb')\n",
    "pickle.dump(LogisticRegression_classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_classifier = open('pickled_algos/MultinomialNB.pickle', 'wb')\n",
    "pickle.dump(MNB_classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_classifier = open('pickled_algos/LinearSVC.pickle', 'wb')\n",
    "pickle.dump(LinearSVC_classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cell'></a>\n",
    "<h2>Correr desde aquí</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta clase contiene el sistema de votación, el cual utiliza los modelos preentrados para clasificar tweets como positivos o negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    \n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "    \n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importa el dataset que se utilizaron para entrenar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_f = open ('pickled_algos/documents.pickle', 'rb')\n",
    "documents = pickle.load(documents_f)\n",
    "documents_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features5k_f = open('pickled_algos/word_features5k.pickle', 'rb')\n",
    "word_features = pickle.load(word_features5k_f)\n",
    "word_features5k_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan los modelos para el sistema de votación, estos fueron preentrenados, como se puede ver en las celdas de arriba. Son 5 a fin de evitar un empate durante la votación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file = open('pickled_algos/originalNB.pickle', 'rb')\n",
    "classifier = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasuo\\.conda\\envs\\computer_vision\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\yasuo\\.conda\\envs\\computer_vision\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\yasuo\\.conda\\envs\\computer_vision\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\yasuo\\.conda\\envs\\computer_vision\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.feature_extraction.dict_vectorizer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction. Anything that cannot be imported from sklearn.feature_extraction is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\yasuo\\.conda\\envs\\computer_vision\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator DictVectorizer from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "open_file = open('pickled_algos/MultinomialNB.pickle', 'rb')\n",
    "MNB_classifier = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasuo\\.conda\\envs\\computer_vision\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator BernoulliNB from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "open_file = open('pickled_algos/BernoulliNB.pickle', 'rb')\n",
    "BernoulliNB_classifier = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasuo\\.conda\\envs\\computer_vision\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\yasuo\\.conda\\envs\\computer_vision\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "open_file = open('pickled_algos/LogisticReg.pickle', 'rb')\n",
    "LogisticRegression_classifier = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasuo\\.conda\\envs\\computer_vision\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.svm.classes module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.svm. Anything that cannot be imported from sklearn.svm is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\yasuo\\.conda\\envs\\computer_vision\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator LinearSVC from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "open_file = open('pickled_algos/LinearSVC.pickle', 'rb')\n",
    "LinearSVC_classifier = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función llama al clasificador de comentarios y determina si el texto introducido es positivo o negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    feats = find_features(text)\n",
    "    \n",
    "    return voted_classifier.classify(feats), voted_classifier.confidence(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "voted_classifier = VoteClassifier(classifier,\n",
    "                                  LinearSVC_classifier, \n",
    "                                  MNB_classifier, \n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 1.0)\n",
      "('neg', 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(sentiment('This movie was awesome! The acting was great, plot was wonderful, and there were pythons'))\n",
    "print(sentiment('This movie was utter junk. There were absolutely 0 pythons. I do not see what the point was at all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta celda se llama a la API de Twitter, para recabar tweets y analizarlos con la función sentiment. La celda se detiene luego de 20 segundos, pero este tiempo puede ser modificado si se desea adquirir una mayor o menor cantidad de tweets (en la función 'on_data'). De no existir el límite de tiempo, la celda correría indefinidamente y la ejecución tendría que detenerse manualmente. Las clasificaciones con una confianza superior al 80% son enviadas a un archivo 'twitter-out.txt', el cual sirve para graficar el sentimiento. En twitterstream.filter.track() se especifica el término que la API de twitter va a filtrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Hae__baee Happy Mark Lee Day!!🥳\n",
      "tq for the giveawayy\n",
      "\n",
      "#HappyMarkDay\n",
      "#MarkInOurHearts\n",
      "#마크_생일이라_날이_MARK다… https://t.co/Qkc40YEBVE neg 0.8\n",
      "RT @NTRFansCampaign: Happy Birthday Rockstar @ThisIsDSP From @tarak9999 Fans\n",
      "\n",
      "#NannakuPrematho Title Song Will Stay In Our Hearts For Ever… neg 0.8\n",
      "RT @SpiritOfCongres: Happy friendship day 🎆 \n",
      "\n",
      "#ModiCronyBhaiBhai https://t.co/WCBJ5tlphe neg 0.8\n",
      "RT @JJHLOOKS: happy birthday mark!\n",
      "#HappyMarkDay\n",
      "#MarkInOurHearts\n",
      "#스물둘_마크가_빛날_시간 https://t.co/eVMWRrSH5j pos 0.8\n",
      "@StoudemireAmar happy national gf day bby pos 0.8\n",
      "RT @Larc92: Dragon\n",
      "For now here is a mini project I did with @austinbatchart for Dragon Trapper's Lodge. \n",
      "I'm happy that I got a fantastic… pos 0.8\n",
      "@__S_H_A_W__ Happy prendshipday mawaaa🥵🥵\n",
      "#RiseOfPanIndiaStarPrabhas\n",
      "#Prabhas #RadheShyam neg 0.8\n",
      "RT @urstrulyMahesh: Happy birthday, rockstar @ThisIsDSP!! Keep ruling the charts with your phenomenal music. Have a great day!! Stay safe 🤗… pos 1.0\n",
      "RT @jasdestinyy: happy national gfs day 😌@anthony_gurtler pos 0.8\n",
      "RT @syjadvocate: thinking about how yejin once said she didn’t want to surround her career with controversies/dating rumors coz she wouldn’… neg 0.8\n",
      "RT @sb19_pinuno: Happy Monthsary to this hardworking fandom! We have gone far from where we started, but this ain't the end yet, and I hope… neg 0.8\n",
      "RT @RadheShyamFilm: Here's wishing our director @director_radhaa a very Happy Birthday! \n",
      "\n",
      "#HBDRadhaKrishnaKumar #RadheShyam https://t.co/4j… neg 1.0\n",
      "@ForeverStros happy birthday!! pos 0.8\n",
      "RT @patrick_gleason: Happy #Spidermanday, Parker. https://t.co/ZX2DdJrZmS neg 0.8\n",
      "RT @UrsVamsiShekar: Your combination delivered all musical Blockbusters 🎶💥 #HappyBirthdayDSP pos 0.6\n",
      "RT @johfamcokr: Happy birthday mama suh!! 🥳🥳 \n",
      "\n",
      "#MamaSuhDay @NCTsmtown_127 https://t.co/csVDyLsmNp neg 0.6\n",
      "@RahulKu38108843 @RUPESHWARSARKAR Happy Friendship day neg 0.8\n",
      "@kilt0408 さり気無くゴボウ要素組み込んでて良かったよ😆✨✨\n",
      "どうぞどうぞ、（エアーで）たーんとお食べ！！happy birthday to you💕 neg 0.8\n",
      "Friends buy you food, best friends eat your food. \n",
      ".\n",
      ".\n",
      "Happy Friendship Day \n",
      ".\n",
      ".\n",
      ".\n",
      "In frame - Cookies and Milk 🥛🍪\n",
      ".… https://t.co/kU6HRc8C4Y pos 0.8\n",
      "RT @isudheerbabu: Happy Birthday @ThisIsDSP ... Keep those rocking albums coming 🤗 neg 0.8\n",
      "@zhflrt https://t.co/9hqgwjuhat &lt;3 neg 0.8\n",
      "RT @illuwalaminati: Happy \" Aaj gaadi tera bhai chalayega \" day.\n",
      "\n",
      "#FriendshipGoals #HappyFriendshipDay2020 neg 0.8\n",
      "RT @AshTanTrendsOFC: UPDATE : We are now on seventh spot in PH trends with fifteen thousand tweets!! \n",
      "\n",
      "Happy Tweeting Milkies!! \n",
      "\n",
      "ASHTAN Bi… neg 0.8\n",
      "@SB19PATROL @Graceparaiso8 @SB19Official 32. SYEMPRE MERON NA..😌\n",
      "Happy SB19xATinDay\n",
      "@SB19Official\n",
      "#GITZHanggangSaHuli neg 0.8\n",
      "RT @JohnnyThorFish: Medyo may pagkabuang tong si Twitter minsan ano? Kapag marami at maingay kami, ang tagal o mahirap makapasok sa TL pero… neg 0.8\n",
      "RT @oofstreet: happy national gf day 2 me i’m fucking awesome pos 0.8\n",
      "RT @urstrulyMahesh: Happy birthday, rockstar @ThisIsDSP!! Keep ruling the charts with your phenomenal music. Have a great day!! Stay safe 🤗… pos 1.0\n",
      "RT @NCT_OFFICIAL_JP: 誕生日おめでとう！マーク！！\n",
      "HAPPY BIRTHDAY ♡ MARK !!\n",
      "\n",
      "#HAPPYMARKDAY\n",
      "#MARK #NCT https://t.co/quMtsY6vnG neg 0.8\n",
      "@whatchelsysays @shreix @Palpendikular @monicas_7777 @PritiMhatre6 @pubgkadeewana @_chashmish @PunManDhan… https://t.co/jBOmb6MxeO neg 0.8\n",
      "jap skang happy meal dapat we bare bear punya toys ke,,,, SINI TAKDE MCD 😭😭😭😭 pos 0.6\n",
      "RT @confuzzled2: Happy ako na okay sila.\n",
      "\n",
      "#AllOutDENLIE\n",
      "\n",
      "@MyJaps @aldenrichards02 https://t.co/ShLL8d2JrH neg 0.8\n",
      "RT @demseokdimple: Happy to see the smiley stamp has remained apparent with TinyTan Jhope too 🥺 https://t.co/Xpq3KaSgby neg 0.8\n",
      "i got squidward. im so happy pos 0.8\n",
      "RT @NCTsmtown: 🎂HAPPY BIRTHDAY TO #MARK\n",
      "WE💚YOU\n",
      "\n",
      "#HAPPYMARKDAY\n",
      "#마크 #NCT #NCT127 https://t.co/6pO54vfUkv neg 0.8\n",
      "@urixvii @pledis_17 happy wedding🤗💕 pos 0.8\n",
      "@KwinFae Happy birthday queen neg 1.0\n",
      "RT @Chaudha86608429: #CMका_जन्मदिन_बने_रोजगारदिन\n",
      "તમે પણ મીઠાઇ ખાવો\n",
      "અને અમને પણ શિક્ષકોની ભર્તી પુરી કરીને મીઠાઇ ખાવાનો લાભ આપો સાહેબ\n",
      "Happy… neg 0.8\n",
      "RT @winwinspics: happy birthday to nct’s gem mark lee ❤️\n",
      "#HappyMarkDay\n",
      "#MarkInOurHearts\n",
      "#스물둘_마크가_빛날_시간 https://t.co/XgD6p9ObS4 pos 1.0\n",
      "will continue to use this video for every reggie occasion out there. happy bday my guy, thanks for being dum. we mi… https://t.co/Fm4iFZGtu1 neg 1.0\n",
      "@NCTsmtown_127 HAPPY BIRTHDAY MARKKKK👑🍉🎂💚💚💚 neg 0.8\n",
      "RT @CatladyLovinFL: Orange says...\n",
      "\n",
      "Orange you glad we’re furriends #CatsOfTwitter 💙\n",
      "\n",
      "Happy #KittyLoafMonday 🐾 https://t.co/rizdr892se neg 0.8\n",
      "RT @ZOMBIEJuicee: Did they ban TikTok yet cause I’d actually be happy when they do lol pos 0.8\n",
      "@Arshitjain01 Happy friendship day 😊💕 neg 0.8\n",
      "RT @NCT_OFFICIAL_JP: 誕生日おめでとう！マーク！！\n",
      "HAPPY BIRTHDAY ♡ MARK !!\n",
      "\n",
      "#HAPPYMARKDAY\n",
      "#MARK #NCT https://t.co/quMtsY6vnG neg 0.8\n",
      "RT @_ItsDulcebruhh: happy national girlfriends day to myself cause i held that shit down even when i wasn’t supposed too . neg 0.6\n",
      "@Reptarro Happy birthday Elliott https://t.co/HEb7xXrP5L neg 0.8\n",
      "@itsgodisawoman happy birthday!! pos 0.8\n",
      "Happy Friendship Day.....💕💕💕💕 https://t.co/HQ8P8SiV8X neg 0.8\n",
      "RT @Shak_dogar: مارننگ💞\n",
      "\n",
      "Happy #2ndday of #EidAlAdha neg 0.8\n",
      "RT @JJHTweets: Happy Sunday folks.\n",
      "\n",
      "#WearAMask #WearADamnMask https://t.co/3rcepLlpXO neg 0.8\n",
      "@aditishaharwale Aditi\n",
      "Happy friendship day 🌹 neg 0.8\n",
      "RT @jasminericegirl: happy national gf day to all the drunk women i've met in bathrooms who unconditionally loved and supported me pos 1.0\n",
      "RT @Himansh231272: @Harpals41581318 @vijayrupanibjp Happy birthday @vijayrupanibjp neg 0.8\n",
      "@sinnnsro happy gf day b my gf pos 0.8\n",
      "@Jackiee_Janett happy birthday 🥳💗 pos 0.8\n",
      "@vishalp09304790 Happy friendship day neg 0.8\n",
      "@BashirAhmaad Happy birthday to my king. May wish you long life ameen. https://t.co/I3dD4hjdaz neg 1.0\n",
      "RT @tiarasuppport: Happy birthday papa Deddy🎉🎉 semoga bahagia selalu dan semakin sukses😊. Sosok ayah yang luar biasa buat Tiara Andini❤️\n",
      "@i… neg 0.8\n",
      "@karyyylll Happy birthday pre❤️ neg 0.8\n",
      "@maaya_morinaga Happy Birthday ㊗️🎊🎉🎂🍾 neg 0.8\n",
      "RT @AnushkaSFanCIub: \"Old friends or new, that’s what they do. Bring you happiness. This one’s for all our friends. To the ones we’ve grown… pos 0.8\n",
      "#wizonestruggles\n",
      "happy #NationalGirlfriendDay https://t.co/OxUVhsX3Nt pos 0.8\n",
      "RT @Sidemen: 🎉 Happy birthday @Vikkstar123! 🎉 https://t.co/4KncFA9VMg neg 0.8\n",
      "RT @chaaa1920: July 19: \"I miss my fans more today ❤️\"\n",
      "that was 1 year since x1 &amp; the day he did short live saying it's an anniversary of t… neg 1.0\n",
      "RT @DarkSisterHive: When my old nigga makes a happy birthday post for my new nigga I’ll know my vagina is the Final Boss. Ms. Lisa Bonet -… pos 0.8\n",
      "RT @narendramodi: The Smart India Hackathon offered yet another glimpse of India’s talented Yuva Shakti. It is these youngsters who will ta… pos 0.8\n",
      "RT @mefeater: 🎉Happy 27th birthday🎉to this young man who stole our hearts in shows like Victorious and Insecure with his acting and musical… neg 1.0\n",
      "RT @gulaaaaaaa: RT kalau korang tak dapat wish “Happy Girlfriend’s Day” hshshhs neg 0.6\n",
      "💚💙 https://t.co/Vhek1GthIy neg 0.8\n",
      "RT @humorandanimals: when you don't know what you're doing but you're happy to be involved\n",
      "(jukin copyright management) https://t.co/l895iR… pos 0.8\n",
      "जन्मदिन की शुभकामनाएं\n",
      "\n",
      "#HBD_CM_From_Pharmacist \n",
      "#GovtPharmacist_Wishes_Rupaniji neg 0.8\n",
      "Happy Birthday Rockstar @ThisIsDSP From @tarak9999 Fans.❣️❣️\n",
      "\n",
      "Thank You For All Blockbuster Albums Which You Compos… https://t.co/4tE31BNW3y neg 0.8\n",
      "RT @ErUmang99: Gujarat students wants Justice..\n",
      "\n",
      "On your Birthday we request you to declare results of the pending exams...\n",
      "\n",
      "Happy Birthday… neg 0.8\n",
      "RT @urstrulyMahesh: Happy birthday, rockstar @ThisIsDSP!! Keep ruling the charts with your phenomenal music. Have a great day!! Stay safe 🤗… pos 1.0\n",
      "RT @NCTsmtown: 🎂HAPPY BIRTHDAY TO #MARK\n",
      "WE💚YOU\n",
      "\n",
      "#HAPPYMARKDAY\n",
      "#마크 #NCT #NCT127 https://t.co/6pO54vfUkv neg 0.8\n",
      "RT @narendramodi: The Smart India Hackathon offered yet another glimpse of India’s talented Yuva Shakti. It is these youngsters who will ta… pos 0.8\n",
      "RT @NCT_OFFICIAL_JP: 誕生日おめでとう！マーク！！\n",
      "HAPPY BIRTHDAY ♡ MARK !!\n",
      "\n",
      "#HAPPYMARKDAY\n",
      "#MARK #NCT https://t.co/quMtsY6vnG neg 0.8\n",
      "RT @OsmanTibyan: Happy Eid 🐛 https://t.co/O58RLInVOk neg 0.8\n",
      "RT @isaacmcblessedL: Remember that very little is needed to make a happy life.\n",
      "#NBSSNL https://t.co/2XKxVEA6n9 pos 0.8\n",
      "RT @JoanneMsCanada: Here is an update about our Spotify ad! That massive number is already a lot! \n",
      "\n",
      "Question asked: Is it linked to the alb… neg 0.8\n",
      "RT @YOONADDICTcom: Remember when YoonA said \"SNSD exist because of SONE\"? 💗\n",
      "\n",
      "Happy 12th anniversary fellow sones 🎉\n",
      "\n",
      "#SNSD #소녀시대 #GG4EVA\n",
      "htt… pos 0.6\n",
      "@NCTsmtown_127 wishing that you're always happy my sunshineeee 💖💖💖 pos 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @NOLIMITLAF7ARE: I said #HAPPY #NATIONAL #GIRLFRIEND #DAY https://t.co/Xcp7sE5dZo neg 0.8\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d6722d989a66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mtwitterStream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlistener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mtwitterStream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"happy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\computer_vision\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, follow, track, is_async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filter_level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'delimited'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_async\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[1;32m~\\.conda\\envs\\computer_vision\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_start\u001b[1;34m(self, is_async)\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\computer_vision\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[1;31m# call a handler first so that the exception can be logged.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\computer_vision\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\computer_vision\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[1;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\computer_vision\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[1;34m(self, resp)\u001b[0m\n\u001b[0;32m    349\u001b[0m             \u001b[0mnext_status_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnext_status_obj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_status_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[1;31m# # Note: keep-alive newlines might be inserted before each length value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\computer_vision\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-d6722d989a66>\u001b[0m in \u001b[0;36mon_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mall_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mtweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0msentiment_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentiment_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "#consumer key, consumer secret, access token, access secret.\n",
    "ckey=\"yNQvbItoIh2KM6CvvzGAYHUee\"\n",
    "csecret=\"GQb43q0jjSKDgrZjJwt4V4pFJMNHBySbkYZmujyL0JSkTByDBx\"\n",
    "atoken=\"3310850076-IZaW3mqt8meusAQk3XGgojsNekzK4sr9bpbgxBv\"\n",
    "asecret=\"p8U14zI4dzf6hx57MPGeitlFuquocbnsxuXgGWGyiqIbh\"\n",
    "\n",
    "class listener(StreamListener):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        if (time.time() - self.start_time) < 20: \n",
    "            all_data = json.loads(data)\n",
    "\n",
    "            tweet = all_data[\"text\"]\n",
    "            sentiment_value, confidence = sentiment(tweet)\n",
    "            print(tweet, sentiment_value, confidence)\n",
    "        \n",
    "            if confidence*100 >= 80:\n",
    "                output = open('twitter-out.txt', 'a')\n",
    "                output.write(sentiment_value)\n",
    "                output.write('\\n')\n",
    "                output.close()\n",
    "\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "        \n",
    "auth = OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken, asecret)\n",
    "\n",
    "twitterStream = Stream(auth, listener())\n",
    "\n",
    "twitterStream.filter(track=[\"happy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta celda grafica el output de la celda anterior. Si hay tweets negativos, la línea baja, si hay tweets positivos, la linea sube. En el video, Sentdex menciona que el algoritmo de clasificación tiene un sesgo hacia la clasificación de tweets como negativos, además de que luego de revisar más de cerca los tweets, se puede observar que incluso clasifica tweets que no están en inglés, por lo tanto, se modificó el decremento que ocurre cuando hay tweets negativos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xU9Z3/8df3TAIFFMhMDJGL9ZKwW2tLYoMKXfFnydbd1oJQtaioBIUAggiKIog3RFAElJIIBEQFL9UuEbStS1MQXFPbKGJBq9y8QMGGZEBBAknmfH9/jB2MgOQ6Z5J5P/9xzncu5zOfh7zn5Fy+x1hrLSIiElccrwsQEZHoU/iLiMQhhb+ISBxS+IuIxCGFv4hIHFL4i4jEoQSvC6iLXbt21et9ycnJlJWVNXI1LYt6VDvqU+2oTycWrR517tz5mOPa8hcRiUMKfxGROKTwFxGJQwp/EZE4pPAXEYlDnp3ts2HDBpYsWYLruvTt25fLLrvMq1JEROKOJ1v+ruuyePFiJk2axJw5c3jjjTfYuXOnF6WIiMQlT7b8t27dSmpqKp06dQKgd+/elJSU0LVr10Zfl93wJhWtWmErDmF378B0/z6m+zmNvh4RkebEk/APBoMEAoHIciAQYMuWLUe9rqioiKKiIgBmzJhBcnJynddV9tIzfPGPTyLLFjjlmT/itG1X98JbsISEhHr1N96oT7WjPp2Y1z3yJPyPdf8YY8xRY9nZ2WRnZ0eW63M1nL35HgLt2rB3Tyn2dy9i3/o/yn6zBOcXg+r8WS2ZrsisHfWpdtSnE4vLK3wDgQDl5eWR5fLycpKSkppkXcafTEKX72K6noGTezv8sCd25bOEhvXDri/GHjrYJOsVEYllnmz5n3XWWezevZvS0lL8fj/FxcXcfPPNUVm3c+kg3L+VAOA+PqPmc/m/xSS2ikodIiJe8mTL3+fzMXToUKZNm8a4cePo1asX3bp1i8q6zRnpOGPvOeZz7qjLo1KDiIjXPDvP/9xzz+Xcc8/1ZN3mnB/hK1gJgN1XDrs+xZ0T/kGw6/+MObeXJ3WJiERL3F/hazoGMGdn4sxZBoD7+HTswS89rkpEpGnFffj/izmpPeZnVwDg5j3gcTUiIk1L4f81zoBrww82v4f7+ipvixERaUIK/29wZiwCwD49D3vwgMfViIg0DYX/N5hACmbwKADcsVdr/7+ItEgK/2NwLvovaHcyAO7Yq7DV1R5XJCLSuBT+x+F79JnIY3fkQOyGNz2sRkSkcSn8v4Xz+PLIYzfvQeyezzysRkSk8Sj8v4VJSMBXsBLT62IA3EnDsX9/1+OqREQaTuFfC87QcdAxPAW1O3sK9uOjp58WEWlOFP615Ju5BPOjHwPgTrsVu+EvHlckIlJ/Cv86cEbcAT3OA8DNm4bdW36Cd4iIxCaFfx05oybB2ZkA2N8+6W0xIiL1pPCvI+M4+Mbdh+lzCXb9G9jyPV6XJCJSZwr/ejI/uxKqq3En3oD75hqsG/K6JBGRWlP415MJnAIp4Xtj2sVzcHMHYA9VeFyViEjtKPwbwLk/r8ayO+ZX2MrDHlUjIlJ7Cv8GMD4fvoKVOAsKI2PuTVdoNlARiXkK/0ZgHB/OwhWRZfeeMR5WIyJyYgr/RmKMwVnwEvh8sK8cd+FMr0sSETkuhX8jMo6DMzt8L2Bb8jqhYf1w1/we67oeVyYiUpPCv5GZtu1wxt0fWbbPzscuy/ewIhGRoyn8m4A5OwNn1lORZfv6KkJ5D3pYkYhITQr/JmLaJ4XPBLpjRnhgw5u4y5/2tigRka8o/JuYSTsbZ8J0AOwffos98IXHFYmIKPyjwnT/Ps7oKQC44wbjrnzW44pEJN4p/KPE9OgJ/mQA7MvPExrWj9CwftiDX3pcmYjEI4V/FPkeegJnxMQaY+7Yq7DWelSRiMQrhX+UmR/1xplQ88wf++Rcj6oRkXil8PeA6X4OzsIVOPPDcwLZ4j8d2Q204yOPqxOReKDw94gxBuPz4dxZcxoI9/6xuG8UeVSViMQLhb/HzJn/hjO/EGfOMgikAOHdQKFh/QjdO0bHA0SkSSj8Y4Dx+TAntcc3Y1HkBvEA/OMT+Ntb3hUmIi2Wwj/G+EbfhXPbtMiyu/Ah3SJSRBqdwj8GmX/7Ab6ClZhrRkJlZfgWkf/c5XVZItKCKPxjmOnz08hj964R2v8vIo1G4R/DjOML3yDm1G4AuMP7Yz/e4nFVItISKPxjnHEcnEmPRJbdabcSenyGhxWJSEug8G8GzHfahI8BZP1HeGB9Me4Li7UbSETqLaEhb166dClvv/02CQkJdOrUiVGjRtGuXTsACgsLWb16NY7jkJOTQ0ZGBgDbt28nLy+PyspKMjMzycnJwRjT8G8SB8zwCXBuL+zCmdg/rsD+cQX0OA/f6Lu8Lk1EmpkGbfn/8Ic/ZNasWTzyyCOceuqpFBaGpyvYuXMnxcXFzJ49m8mTJ7N48WLcr+5jW1BQQG5uLnPnzuWzzz5jw4YNDf8WccIYg9PzQpybJh0ZfPevuOtexe7XfQJEpPYaFP49evTA5/MB0L17d4LBIAAlJSX07t2bxMREUlJSSE1NZevWrezdu5eKigq6d++OMYY+ffpQUlLS8G8RZ0zGBeG7hE2eBYBdmo87fjD27Tc8rkxEmosG7fb5utWrV9O7d28AgsEg6enpkef8fj/BYBCfz0cgEIiMBwKByA/GsRQVFVFUFJ7nZsaMGSQnJ9ertoSEhHq/N6YlJ3Nw+K3sXxj+EXDnP8QpS17B6eiv80e12B41MvWpdtSnE/O6RycM/6lTp7Jv376jxgcNGkTPnj0BWL58OT6fjwsvvBDguAci63qAMjs7m+zs7MhyWVlZnd7/L8nJyfV+b8zreRFOtzTsa7/H/ull9uRcirNwRZ2Po7ToHjUi9al21KcTi1aPOnfufMzxE4b/lClTvvX51157jbfffpu77747EjiBQIDy8vLIa4LBIH6//6jx8vJy/P66b6VKTSa1C2bQMEJ/ehkIXw9Qnx8AEYkfDdrnv2HDBlasWMEdd9xB69atI+NZWVkUFxdTVVVFaWkpu3fvJi0tjaSkJNq0acPmzZux1rJu3TqysrIa/CUkzMn/beSxO7w/9sv9HlYjIrHM2AacLD5mzBiqq6s56aSTAEhPT2f48OFAeFfQmjVrcByHIUOGkJmZCcC2bdvIz8+nsrKSjIwMhg4dWust1F276je/TTz9CWqrq3FHDows+wpW1up98dSjhlCfakd9OjGvd/s0KPyjTeFfO/bQQdwxgyLLtfkBiLce1Zf6VDvq04l5Hf66wrcFMt9pi5P3YmQ5dPtQD6sRkVik8G+hTKvWOI89F17YW4a78jlvCxKRmKLwb8FM23Y44+4HwL78HO7T83R/YBEBFP4tnjk7A2dUeDoI+/qqyP2BbVWVx5WJiJcU/nHAZF4AJ51cY8wd9UvcV36DrdaPgEg8UvjHCd+cZ8LzAT3yVGTMrngGd+QvPaxKRLyi8I8zpkPSUad+hkYO1L0BROKMwj9O+QpW4sxeGl6orqZ04I+9LUhEokrhH8fMyR1wZiyOLIeG9cP9y1oPKxKRaFH4xzkTOKXGBWF20SysG/KwIhGJBoW/YFq1plNhMWbgdQC4uQM8rkhEmprCXyLMJUcmhHOLVmKrKj2sRkSaksJfIozj4Dz6LAD2N4twR11OKO9B/QiItEAKf6nBtDsJc9ngIwMb3sQddTn2o83eFSUija7R7uErLYfz8ytxT0mFD/6GfX0VAO6Dt4Wfm70Mc3J7L8sTkUagLX85Jue8PjjXjcZZuKLGuDt+MO6a33lUlYg0FoW/fCtjTPiCsHvnRcbsswsIDesXniDui30eVici9aXwl1oxXU7DV7ASkzO2xrh763XhHwFdGyDSrCj8pU7MBRdDytG3hXNzB2Bd14OKRKQ+dMBX6sQ4Dr5p8wHCYe+GIjODurmX4dx8D+YHP/KyRBGpBW35S70Zx8EkJOI8MD8y5s69T38BiDQDCn9pMNOpc/h4wI/7AuEbxYSG9cNuetvjykTkeBT+0mjMdaPDD0Lhg7/uY/cRGtbPw4pE5HgU/tJojOPDGXvPUeOhYf1w177qQUUicjw64CuNypzzo8idwuzhQ7ijrww/XpZP6M+rMd2/Dyd1wPxnf4wxXpYqEtcU/tJkTOvv4MwvxB19BVRXw7YPsNs+AMC++AQAzoKXMI7+ABWJNv2rkyZlfD58jy/HmTLnmM+7uZfp7CARD2jLX6LCnHbWkd1B1kJwD+7EG8PLr6/CXPRfXpYnEne05S9RZ4zBBFIiN5C3y/KPzBXkhjRfkEgUKPzFM+bkDphrRtQYc3MH4N56He6Tcz2qSiQ+aLePeMr5fz/DnnIqNrgH+/TXZg59o4hQxZew/UPMFUNxzuvjXZEiLZCx1lqvi6itXbt21et9ycnJlJWVNXI1LUus9Mj+rQS78S3sa384+ske5+FcMxKTFIh+YV+JlT7FOvXpxKLVo86dj56IEbTlLzHG/LAn5oc9cZNTsb9dUvPJd/+K++5f4QdZOKMmYRL0v69Ifelfj8Qk55IB2MwLMCmnYsv+if3f5Uf+Gtj4Fu7IgZhLB+H0v9rbQkWaKR3wlZhlUk4N/ze5E841I8OTx11wceR5+8rz2L+/61V5Is2awl+aFTP0Fpy7jlww5s6egj3whYcViTRPCn9pVowxmO+GLxgzfX8BgDtuMLa62uPKRJoXhb80W+ZXN0YeuyMHYvfrLwCR2lL4S7NljMFZuCKy7C6apXmCRGqpUcJ/5cqVXHnllXzxxZEtr8LCQsaMGcPYsWPZsGFDZHz79u3ceuutjBkzhieeeIJmdJmBxCBjTHjOoC7fhfffwc29zOuSRJqFBod/WVkZGzduJDk5OTK2c+dOiouLmT17NpMnT2bx4sW4X22RFRQUkJuby9y5c/nss89q/DCI1Jcz4o7I49CwfoQevQf74UadDSRyHA0O/6eeeoprrrmmxo05SkpK6N27N4mJiaSkpJCamsrWrVvZu3cvFRUVdO/eHWMMffr0oaSkpKEliGBSu+LMWXZk4L13cB+ZHD4b6MNN3hUmEqMadJHXW2+9hd/v5/TTT68xHgwGSU9Pjyz7/X6CwSA+n49A4Mil+YFAgGAweNzPLyoqoqioCIAZM2bU+OuiLhISEur93njRInqUnIy75BX25FxaY9h9ZBIpL65rlCuCW0SfokB9OjGve3TCfw1Tp05l376jp9gdNGgQhYWF3HXXXUc9d7z9+HXdv5+dnU12dnZkub7zYGiekRNrST3yFazEfvYPqDyMXfcqdu2rlM6YiHN1Lnblc5hLf4XpWL/5gVpSn5qS+nRiMT+3z5QpU445/umnn1JaWsqECRMAKC8v54477mD69OkEAgHKy8sjrw0Gg/j9/qPGy8vL8fv9dfoiIrVhUruEH1wzErv2VXi7GPftYoDw8unp+CbP8rBCEW/Ve5//aaedxqJFi8jLyyMvL49AIMBDDz1Ex44dycrKori4mKqqKkpLS9m9ezdpaWkkJSXRpk0bNm/ejLWWdevWkZWV1ZjfR6QGYwzOlEePfuLjLdj1f45+QSIxokkmduvWrRu9evVi/PjxOI7DDTfcgPPVTbpvvPFG8vPzqaysJCMjg8zMzKYoQSTCnHYmvoKVuG++hul2JtgQ7n1jcR+fjvnFVTj9rvK6RJGo03z+AsRfj9znC7B/ehkAZ8oczGln1ep98dan+lKfTszrff66wlfikjNoGM7IOwFwp47DfnnA44pEokvhL3HLnNsL89+XA+DecjX2y/0eVyQSPQp/iWvm57+KPHZvuUbTjUjcUPhLXDOtW+PMezGy7A7vj7v2Vf0ISIun8Je4Z1q3xsk78gNgl+Xj3jnMw4pEmp7CXwQwrVrj5P8PdD09PFBeivunVzytSaQpKfxFvmISE/HdMxfngfkA2OcXYv+miQelZVL4i3yD6dQZc/UIANxfT8X9y1qPKxJpfAp/kWNwLv4Z5vIcAOyiWfoBkBZH4S9yHM4lAzCXDgLCPwChcYMJle72uCqRxqHwF/kWTv+rMZcMCC8c+IKy3F9iDx30tiiRRqDwFzkB5/IcnAkPRpbdMYOw1VUeViTScAp/kVow3c/BWbgisuzOucfDakQaTuEvUkvGGFKWvxFe2LyJUN40bwsSaQCFv0gdGGNwpi0IL2z4C3bzJuz2D70tSqQeFP4idWRSTo0cA3BnTsKdPgH7yTaPqxKpG4W/SD2Y7udAtzMiy+4D47Cu62FFInWj8BepJ9/dj+HkvYjpdTEAbu5l2FBIM4JKs6DwF2kA06o1ZsjNkWV3xADc4f0JPXavfgQkpin8RRrIOD6cqfk1Bzetxx3eH1tav/tOizQ1hb9IIzCpXXEWrsC5bx4EUiLj7uQR2OAeDysTOTaFv0gjMcZgOp+Gb8YinMeei4y7d9yAW/I67mu/x1obPi6gK4TFYwleFyDSEpm27XAWrsAd8ys4fAi7cCYA9pn5kdc4Ex/GnPXvXpUocU5b/iJNxBiDM/f54z7vzrgdd2keNhSKYlUiYdryF2lCxnHwFayMLLt/XYc5qT3uq/8Df38Xu+5/wX8K5udXelilxCNt+YtEkXNeH8zZGfjGT4WUzgDYl5YRGtYPW13tcXUSTxT+Ih7xTZuPM35qZNkdOVDXBkjUKPxFPGS+16PGmUG2cKmH1Ug8UfiLeMy0bYeT9yIA9g+/xV37qscVSTxQ+IvEANOqNc7NdwNgl+Vjd3zkcUXS0in8RWKE+UEW5oZxALj3jw0fBP50u8dVSUul8BeJIc4FF8PXLvxyp96Cu3i2DgRLo1P4i8QY38SHcSbNgo4BAOybr+EO7+9xVdLSKPxFYpA5Ix3fzCWYH/eNjLlPztWcQNJodIWvSAxzhozFDrwO99brsW8UYd8oOvLcrKcx7Tt6WJ00Z9ryF4lxpn0SZtDwo8bdW6/DbvvAg4qkJdCWv0gz4PS9FPpeiv18L3y8BXfeA0B4cjgA57HnMG3beVmiNDPa8hdpRkyHJEyP83AWFNYYd8dehbvyOdy/rsO6IeyOj8KniuovAzkOY5vROWS7dtXvlnjJycmUlZU1cjUti3pUO7HUJ+uGIBTCHXX5t77OXHkD5vyLonp8IJb6FKui1aPOnTsfc7zBu33+8Ic/8Oqrr+Lz+Tj33HMZPHgwAIWFhaxevRrHccjJySEjIwOA7du3k5eXR2VlJZmZmeTk5GCMaWgZInHHOD5wfOGbxnzLqaD2hcXYFxbDd9Nwbp+OadU6ilVKrGpQ+G/atIm33nqLRx55hMTERD7//HMAdu7cSXFxMbNnz2bv3r1MnTqVxx57DMdxKCgoIDc3l/T0dKZPn86GDRvIzMxslC8jEo+MMZF7Blg3hJs7AABnegH2vXewy766ufwnW3FvugJnwoOY7ud4Va7EiAbt81+1ahX9+/cnMTERgA4dOgBQUlJC7969SUxMJCUlhdTUVLZu3crevXupqKige/fuGGPo06cPJSUlDf8WIgKE/xrwFazEV7ASk9wJ0+cSnPFTMef1ibzGnTlJ9w6Qhm357969mw8++IDnn3+exMRErr32WtLS0ggGg6Snp0de5/f7CQaD+Hw+AoFAZDwQCBAMBo/7+UVFRRQVhc9rnjFjBsnJyfWqMyEhod7vjRfqUe00yz6d0hcu7Is9fJjglJuo3vI+7siBAKQsf6NJdrs2yz5Fmdc9OmH4T506lX379h01PmjQIFzX5cCBA0ybNo1t27YxZ84c5s2bd9x5SOp6bDk7O5vs7OzIcn0Pjujg04mpR7XT3PtkJ0yHrx0fKB344xq3mWwszb1P0RDzB3ynTJly3OdWrVrF+eefjzGGtLQ0HMdh//79BAIBysvLI68LBoP4/f6jxsvLy/H7/XX5HiLSAMYYnKn5uItmwydbAQjNewDf6Ls8rkyirUH7/Hv27MmmTZuA8GmY1dXVnHzyyWRlZVFcXExVVRWlpaXs3r2btLQ0kpKSaNOmDZs3b8Zay7p168jKymqULyIitWNSu+K7azbOo8+EB979K/Yfn3hblERdg87zr66uJj8/n08++YSEhASuvfZazjknfBbB8uXLWbNmDY7jMGTIkMgZPdu2bSM/P5/KykoyMjIYOnRorfc56jz/pqMe1U5L65Pd8BfcvGkAOHOWYU5q3yif29L61BS83u2ji7wEUI9qqyX2KfToPfDeO+GFrqfj5NyCOe3MBn1mS+xTY/M6/DW9g0icc2762v7+nR+HbyCzTvcRbukU/iJxziQmhq8L6HNJZMwuzccted3DqqSpKfxFBADn2pvwFazEGXknAHbhTOy+8hO8S5orhb+I1GDO7YW5LDxHlzshB/vlAY8rkqag+fxF5CjOz68ktL4YPt2Oe8vVR544tRu++/O8K0wajbb8ReSYfFMePXpw9w5Cw/qF7xXghrAHD+A+PQ9b9s/oFygNoi1/ETkuX8FK7PvvYN95E878d+wTcyLP/Wv2UAD7+iqcERMxP+rtRZlSDwp/EflW5uxMzNnhizRttzOwn27HLjn6rwJ3/gyc+YUYny/aJUo9KPxFpNZM19MxXU+H3j/B7gtCVSUkd8Iuy8eu+1/cEQNw7pwJmtEz5mmfv4jUi+nox5ySijEGM3hUZNydPoGqj7d6WJnUhsJfRBrMGBOeKK5DeJbe4LjrwgeFm8/sMXFH4S8ijcK0Oxnn4SdqDv5Nd+qLVQp/EWk0xnHwFawk5cV1ALjzHsAeqvC4KjkWhb+INDqTkIC5fAgAtmiFt8XIMSn8RaRJOJcMhKRk7IpnCQ3rh7v6Fa9Lkq9R+ItIk3FG3BF5bJ9bSOiOG3CfnIutrvKwKgGFv4g0IXPmv2GuyDkyENyDfaMId+Qvsa7rXWGi8BeRpuX8dEB4quh75tYYdxc87FFFAgp/EYkS0/X08I/AvBfDA+uLsV/u97aoOKbwF5GoMq1b49z7azAGu+olr8uJWwp/EYk60+W7mKz/wP7+RewnmgrCCwp/EfGE+fmVALiPTPa4kvik8BcRT5gu38X8Z384VIHdtN7rcuKOwl9EPGP6hW8R6T52L/b9DR5XE3tC944JT5DXBNdFKPxFxDPmO20wF/0XAO6cu7GHD3lcUWywVZWEhvWDf3zy1UDjr0PhLyKecgaPgrTvAeDOvd/jarxny/fgjro8smyGjMUkJjb6ehT+IuI55/YZ0NEPW97H7iv3uhzP2P2f4068IbJsBg3H+XHfJlmXwl9EPGeMwZnwIFgXd0LOid/QQtnfLIo8dua9iNP30iZbl8JfRGKCSekMKacC4P7+xQZ9lj3wBW7xamxVZWOUFhW2ugr7l7UAOAtXYFq3btL1KfxFJGY4d4fn/7GFS7FVdTvDxW77gNCwfuHpo8cNxi55FHfU5bh/bB73E3AfvTfy2BjT5OtT+ItIzDCtW+Pcch8A9v/+WOv32aoq3Bm3H/u5FxaHT5cs39MoNTYFu/Nj+HAjAM5DT3z7ixuJwl9EYsvZGdAhCfvsfGywdoHtPnhb5LEz9p7wfyc8iPnJkX3m7sQbCI35VUzeVN59bkH4wQ97YvzJUVmnwl9EYooxBmfoOADcKaNOGNZ216ew8yMAnIcWY875Eb6ClZju5+BcNRxn6uPQtl34xYcqauxeiRmb3wPAN2ZK1Fap8BeRmGPOzoBTu0HlYXjvnWO+xlqL++c1uPeMDg98PxPjP+Xoz0rtgu+x53DGTw0PvP9O+AKqGGH/VhJ+cHKHqK5X4S8iMcmZNBMA9+Xnjrn1bwsewT4xJ7Ls++pYwfGY7/XAmfJoZDk0rB+24mAjVVs/dvN7uL8O/yg546J7gZvCX0RikvlOW8zgUbD9Q/jGxG/uqkJsyeuRZWfG4tp95mln4jzy1JHPuXkQodlTsJ/9A+uGGqfwWgoF9+DOvPNIbd3OiOr6Ff4iErPMV1e3unPvwx6qAMC6IeyLS8Iv+F6P8P79wNG7e477mR2ScKYtODLw93dxp4zEzR2Au2gW7rpXcf/wW2wohA2WNdnN5stu6B957OQ17LqG+lD4i0jMMgmJmMuHAGDX/C48uPWDyPPOCXb1HPdzU07FmfcCtP5OjXH7l7XYpfnY5U/jjhiAe8fQ8M3mG/kMIVv2z8hj5/HlmFZNe0HXsSj8RSSmOZcMhM6nhQP5zdciu0qcmUswTv0jzLT+Dr55L+DkvYgzcwmkn33c17rD+2P3lmNdt97rq/F5dw4L13DjrZiEhEb5zLpq0Fo//vhjCgoKqKysxOfzceONN5KWlgZAYWEhq1evxnEccnJyyMjIAGD79u3k5eVRWVlJZmYmOTk5UbmaTUSaL2fIWNwHb8Uunh0ZMx0DjfLZplVraNUa3+0zsKEQfB6EhETch+/E9LoY+9IyANzbw3MOObOewrRPqvf67OHDR9Z9Xp+GFd8ADdryX7ZsGZdffjkzZ87kyiuvZNmycJN27txJcXExs2fPZvLkySxevBj3q1/MgoICcnNzmTt3Lp999hkbNugGDiLy7cwZ6Zgrjkz4VmOffWOux+fD+E/BtO+I74HHcX5+JU7+/9R4jXvr9UemkXi2bnXYnR/hjr4CgJOuH+3phm+Dwt8YQ0VF+CDMwYMHSUoK/xqWlJTQu3dvEhMTSUlJITU1la1bt7J3714qKiro3r07xhj69OlDSUlJw7+FiLR4zk8H4IyZgjPracxXE8BFg0lMxFlQGL5Y7Bt/bdg1vwufMlrL3UHufWMjj9v+98BGrbOuGrTb5/rrr2fatGksXboU13V54IEHAAgGg6Snp0de5/f7CQaD+Hw+AoEjzQsEAgSDweN+flFREUVFRQDMmDGD5OT6XfackJBQ7/fGC/WodtSn2mmyPv3kvxv/M2srpRNu3vN8PnMy1bt2cPK1I/l81t0AtCtZS9ufX/Gtb/8ifwYV//qo36whsW07kr9xwDmaThj+U6dOZd++fUeNDxo0iI0bN3L99ddzwQUXUFxczPz585kyZcpxj4zX9Yh5dnY22dnZkeWysrI6vf9fkpOT6/3eeKEe1Y76VDstuk833YUBDhA+U8cdOZD9i+awf1H4gjPn/jzMqd1qvMV+vjudRYoAAAcHSURBVBf3jyu/ej6f8i/2k9yqdVR61Llz52OOnzD8p0w5/lwT8+bNIycnvB+uV69eLFgQ3v8VCAQoLz9yN55gMIjf7z9qvLy8HL/fX7tvICISY0xCAmbYbdiCRyJj7t034Ty4EHNK6pGx264PPzijO+bUrtEu85gatM/f7/fz/vvvA7Bp0yZSU8NfNisri+LiYqqqqigtLWX37t2kpaWRlJREmzZt2Lx5M9Za1q1bR1ZWVsO/hYiIR5zz+uBMmoXJObI/3500HPtu+Him/eLInhPn1geiXt/xNGiff25uLkuWLMF1XRITE8nNzQWgW7du9OrVi/Hjx+M4DjfccAPOV+fj3njjjeTn51NZWUlGRgaZmZkN/xYiIh4yZ6RjzkiH3n0JTbsVPt6CO29qzdfk3ILxcB//Nxkbi5NbH8euXbvq9b4Wvf+xkahHtaM+1U6898l9cQl2VWGNMeex5zD/mlqa6PXoePv8dYWviEgjc67IwXn0mchFXObq3BrBHwu8ua5YRKSFM+1Oxgy7DYbdduIXe0Bb/iIicUjhLyIShxT+IiJxSOEvIhKHFP4iInFI4S8iEocU/iIicUjhLyISh5rV9A4iItI44mLLf+LEiV6XEPPUo9pRn2pHfToxr3sUF+EvIiI1KfxFROJQXIT/128FKcemHtWO+lQ76tOJed0jHfAVEYlDcbHlLyIiNSn8RUTiUIu+mcuGDRsi9xju27cvl112mdclRU1ZWRl5eXns27cPYwzZ2dn87Gc/48CBA8yZM4c9e/ZwyimnMG7cOE466SQACgsLWb16NY7jkJOTQ0ZGBgDbt28nLy+PyspKMjMzycnJwRjj5ddrdK7rMnHiRPx+PxMnTlSfjuHLL79k/vz57NixA2MMI0eOpHPnzurT17zyyiusXr0aYwzdunVj1KhRVFZWxmaPbAsVCoXs6NGj7WeffWarqqrsbbfdZnfs2OF1WVETDAbttm3brLXWHjx40N588812x44ddunSpbawsNBaa21hYaFdunSptdbaHTt22Ntuu81WVlbaf/7zn3b06NE2FApZa62dOHGi/fDDD63runbatGl2/fr13nypJvTyyy/bRx991E6fPt1aa9WnY/j1r39ti4qKrLXWVlVV2QMHDqhPX1NeXm5HjRplDx8+bK21dtasWXbNmjUx26MWu9tn69atpKam0qlTJxISEujduzclJSVelxU1SUlJnHnmmQC0adOGLl26EAwGKSkp4aKLLgLgoosuivSkpKSE3r17k5iYSEpKCqmpqWzdupW9e/dSUVFB9+7dMcbQp0+fFtfH8vJy1q9fT9++fSNj6lNNBw8e5O9//zs/+clPAEhISKBdu3bq0ze4rktlZSWhUIjKykqSkpJitkctdrdPMBgkEAhElgOBAFu2bPGwIu+Ulpby0UcfkZaWxueff05SUhIQ/oH44osvgHC/0tPTI+/x+/0Eg0F8Pt9RfQwGg9H9Ak3sySefZPDgwVRUVETG1KeaSktLad++Pfn5+XzyySeceeaZDBkyRH36Gr/fzy9+8QtGjhxJq1at6NGjBz169IjZHrXYLX97jDNYW8p+xbo4dOgQs2bNYsiQIbRt2/a4rztWv75tvKV4++236dChQ+SvpBOJ1z6FQiE++ugjfvrTn/Lwww/TunVrXnrppeO+Ph77dODAAUpKSsjLy2PBggUcOnSIdevWHff1XveoxW75BwIBysvLI8vl5eWRX994UV1dzaxZs7jwwgs5//zzAejQoQN79+4lKSmJvXv30r59e+DofgWDQfx+/zH76Pf7o/tFmtCHH37IW2+9xTvvvENlZSUVFRXMnTtXffqGQCBAIBCIbKlecMEFvPTSS+rT12zcuJGUlJRID84//3w2b94csz1qsVv+Z511Frt376a0tJTq6mqKi4vJysryuqyosdYyf/58unTpwqWXXhoZz8rKYu3atQCsXbuWnj17RsaLi4upqqqitLSU3bt3k5aWRlJSEm3atGHz5s1Ya1m3bl2L6uPVV1/N/PnzycvL45ZbbuGcc87h5ptvVp++oWPHjgQCAXbt2gWEg65r167q09ckJyezZcsWDh8+jLWWjRs30qVLl5jtUYu+wnf9+vU89dRTuK7LxRdfzMCBA70uKWo++OAD7r77bk477bTI7q6rrrqK9PR05syZQ1lZGcnJyYwfPz5y2tny5ctZs2YNjuMwZMgQMjMzAdi2bRv5+flUVlaSkZHB0KFDW+QutPfee4+XX36ZiRMnsn//fvXpGz7++GPmz59PdXU1KSkpjBo1Cmut+vQ1L7zwAsXFxfh8Pk4//XRGjBjBoUOHYrJHLTr8RUTk2Frsbh8RETk+hb+ISBxS+IuIxCGFv4hIHFL4i4jEIYW/iEgcUviLiMSh/w+9IB4hhttbZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style.use('ggplot')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "def animate(i):\n",
    "    pullData = open(\"twitter-out.txt\",\"r\").read()\n",
    "    lines = pullData.split('\\n')\n",
    "    \n",
    "    xar = []\n",
    "    yar = []\n",
    "    \n",
    "    x = 0\n",
    "    y = 0\n",
    "    \n",
    "    for l in lines:\n",
    "        x += 1\n",
    "        if 'pos' in l:\n",
    "            y += 1\n",
    "        elif 'neg' in l:\n",
    "            y -= 0.3\n",
    "        xar.append(x)\n",
    "        yar.append(y)\n",
    "    ax1.clear()\n",
    "    ax1.plot(xar,yar)\n",
    "ani = animation.FuncAnimation(fig, animate, interval=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
