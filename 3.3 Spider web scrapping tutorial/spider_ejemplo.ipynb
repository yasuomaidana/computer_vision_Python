{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spider tutorial\n",
    "https://www.w3schools.com/xml/xpath_syntax.asp\n",
    "Notacion Xpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__='Yasuo'\n",
    "from scrapy.item import Field\n",
    "from scrapy.item import Item\n",
    "from scrapy.spiders import Spider\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.loader import ItemLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pregunta(Item):\n",
    "    pregunta= Field()\n",
    "    id = Field() #Numero de pregunta\n",
    "\n",
    "class StackOverSpider(Spider): #para web scrappers sencillos es de clase Spider\n",
    "    name=\"MiPrimerSpider\"\n",
    "    start_urls=['https://stackoverflow.com/questions'] #En forma de lista, como es sencillo sera de 1 solo elemento\n",
    "    def parse(self,response): #response esta en formato xml es la respuesta de la web es invocada por el framework\n",
    "        sel=Selector(response) #selector\n",
    "        #ver imagen\n",
    "        preguntas = sel.xpath('//div[@id=\"questions\"]/div') #acepta otros formatos como css\n",
    "        ##preguntas es de tipo lista\n",
    "        \n",
    "        #Iterar sobre preguntas\n",
    "        for i,element in enumarate(preguntas):\n",
    "            item=ItemLoader(Pregunta(),element)#recibe clase de estructura del item y elemento donde se tiene el xpath\n",
    "            item.add_xpath('pregunta','.//h3/a/text()')#campo al que queremos agregar el xpath\n",
    "            item.add_value('id',i)\n",
    "            yield item.load_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inser image into jupyter #![image.png](estWeb.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](estWeb.png)\n",
    "![image.png](pregWeb.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yield is a keyword in Python that is used to return from a function without destroying the states of its local variable and when the function is called, the execution starts from the last yield statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running spider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapy 1.6.0 - no active project\n",
      "\n",
      "Unknown command: crawl\n",
      "\n",
      "Use \"scrapy\" to see available commands\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasuo\\.conda\\envs\\computer_vision\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from scrapy.cmdline import execute\n",
    "execute(['scrapy','crawl','spider_ejemplo'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
